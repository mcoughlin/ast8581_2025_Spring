{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1920,\n",
    "        'height': 1080,\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Week 9 (Wednesday), AST 8581 / PHYS 8581 / CSCI 8581 / STAT 8581: Big Data in Astrophysics\n",
    "\n",
    "### Michael Coughlin <cough052@umn.edu>\n",
    "\n",
    "With contributions totally ripped off from Ashley Villar (Harvard) and Vanessa Boehm (UC Berkeley and LBNL) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Where are we headed?\n",
    "\n",
    "Foundations of Data and Probability -> Statistical frameworks (Frequentist vs Bayesian) -> Estimating underlying distributions -> Analysis of Time series (periodicity) -> Analysis of Time series (variability) -> Analysis of Time series (stochastic processes) -> Gaussian Processes -> Decision Trees / Regression -> Dimensionality Reduction  -> Principle Component Analysis -> Clustering / Density Estimation / Anomaly Detection -> Supervised Learning -> <b> Deep Learning </b> -> Introduction to Databases - SQL -> Introduction to Databases - NoSQL -> Introduction to Multiprocessing -> Introduction to GPUs -> Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "An autoencoder is a type of neural network which we will use to reduce the dimensionality of our data.\n",
    "\n",
    "It is one example of a larger class of “representation learning” in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An Auto-Encoder consists of two networks: \n",
    "\n",
    "1.   An encoder network that takes the data, $x$, and maps it to a lower-dimensional latent space. We will call this network $f$ and its network parameters $\\phi$.\n",
    "2.   A decoder network that takes the encoded data, $z$, and maps it back to the data space. We will call the result of the reconstruction $x'$, the decoder network $g$ (for generator) and its network parameters $\\psi$.\n",
    "\n",
    "$$ x' = g_\\psi(f_\\phi(x)) \\tag{1}$$\n",
    "\n",
    "An Auto-Encoder is trained to minimize the reconstruction error between the input $x$ and the reconstruction $x'$.\n",
    "\n",
    "$$ \\mathcal{L}_{AE}(\\phi,\\psi) = ||x-g_\\psi(f_\\phi(x))||^2_2 \\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='figures/autoencoder.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to fit a model using MOO\n",
    "\n",
    "- Model to fit the data (e.g. physics).\n",
    "- Objective Function (or ‘loss/cost function’) which is a metric that you will choose to quantify how well the model fits the data (e.g. chi-squared).\n",
    "- Optimization Method which you will use to find the best model (e.g. gradient descent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjgT74iXu-KP",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# In-class warm-up: Training an autoencoder for galaxies\n",
    "\n",
    "Let's lower the resolution of our images and only keep one filter. Plot an example of the lower resolution galaxies.\n",
    "\n",
    "Next, flatten each image into a 1D array. Then rescale the flux of the images such that the mean is 0 and the standard deviation is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9TS8c_-lg55",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Taken from https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "\n",
    "def to_categorical(y, num_classes=None, dtype=\"float32\"):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "\n",
    "    E.g. for use with `categorical_crossentropy`.\n",
    "\n",
    "    Args:\n",
    "        y: Array-like with class values to be converted into a matrix\n",
    "            (integers from 0 to `num_classes - 1`).\n",
    "        num_classes: Total number of classes. If `None`, this would be inferred\n",
    "          as `max(y) + 1`.\n",
    "        dtype: The data type expected by the input. Default: `'float32'`.\n",
    "\n",
    "    Returns:\n",
    "        A binary matrix representation of the input as a NumPy array. The class\n",
    "        axis is placed last.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    >>> a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "    >>> print(a)\n",
    "    [[1. 0. 0. 0.]\n",
    "     [0. 1. 0. 0.]\n",
    "     [0. 0. 1. 0.]\n",
    "     [0. 0. 0. 1.]]\n",
    "\n",
    "    >>> b = tf.constant([.9, .04, .03, .03,\n",
    "    ...                  .3, .45, .15, .13,\n",
    "    ...                  .04, .01, .94, .05,\n",
    "    ...                  .12, .21, .5, .17],\n",
    "    ...                 shape=[4, 4])\n",
    "    >>> loss = tf.keras.backend.categorical_crossentropy(a, b)\n",
    "    >>> print(np.around(loss, 5))\n",
    "    [0.10536 0.82807 0.1011  1.77196]\n",
    "\n",
    "    >>> loss = tf.keras.backend.categorical_crossentropy(a, a)\n",
    "    >>> print(np.around(loss, 5))\n",
    "    [0. 0. 0. 0.]\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype=\"int\")\n",
    "    input_shape = y.shape\n",
    "\n",
    "    # Shrink the last dimension if the shape is (..., 1).\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "\n",
    "    y = y.reshape(-1)\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "M3Gg9-a_lp-V",
    "outputId": "e42eab79-3a72-49bd-8db3-fb33e0f60c10",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.astro.utoronto.ca/~hleung/shared/Galaxy10/Galaxy10_DECals.h5\n",
    "\n",
    "# To get the images and labels from file\n",
    "with h5py.File('Galaxy10_DECals.h5', 'r') as F:\n",
    "    images = np.array(F['images'])\n",
    "    labels = np.array(F['ans'])\n",
    "\n",
    "# To convert the labels to categorical 10 classes\n",
    "labels = to_categorical(labels, 10)\n",
    "\n",
    "labels = labels.astype(np.float32)\n",
    "images = images.astype(np.float32)\n",
    "images = torch.tensor(images)\n",
    "labels = torch.tensor(labels)\n",
    "images = images[:,::6,::6,1]\n",
    "\n",
    "#Plot an example image here\n",
    "plt.imshow(images[0])\n",
    "\n",
    "#Flatten images here\n",
    "images = images.reshape(len(images),-1)\n",
    "\n",
    "#Normalize the flux of the images here\n",
    "images = (images  - torch.mean(images))/torch.std(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6-GabIrvqUc",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Split the training and test set with a 66/33 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXVYGbcMlzed",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "images_train, images_test, labels_train, labels_test = train_test_split(\n",
    "    images, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoOK468Nv4dA",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Understanding the Autoencoder\n",
    "\n",
    "Below is sample of an autoencoder, built in Pytorch. Describe the code line-by-line at your table. Add another hidden layer before and after the encoded (latent) layer (this will be a total of 2 new layers). Choose the appropriate activation function for this regression problem. Make all of the activation functions the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR5y59MfnFF2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module):\n",
    "      # this defines the model\n",
    "        def __init__(self, input_size, hidden_size, hidden_inner, encoded_size):\n",
    "            super(Autoencoder, self).__init__()\n",
    "            print(input_size,hidden_size,encoded_size)\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.encoded_size = encoded_size\n",
    "            self.hidden_inner = hidden_inner\n",
    "            self.hiddenlayer1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "\n",
    "            # ADD A LAYER HERE\n",
    "            \n",
    "            self.encodedlayer = torch.nn.Linear(self.hidden_inner, self.encoded_size)\n",
    "            self.hiddenlayer3 = torch.nn.Linear(self.encoded_size, self.hidden_inner)\n",
    "            \n",
    "            # ADD A LAYER HERE\n",
    "            \n",
    "            self.outputlayer = torch.nn.Linear(self.hidden_size, self.input_size)\n",
    "            # some nonlinear options\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "            self.softmax = torch.nn.Softmax()\n",
    "            self.relu = torch.nn.ReLU()\n",
    "        def forward(self, x):\n",
    "\n",
    "            # Change ACTIVATION? to your activation function\n",
    "            layer1 = self.hiddenlayer1(x)\n",
    "            activation1 = self.ACTIVATION?(layer1)\n",
    "            layer2 = self.hiddenlayer2(activation1)\n",
    "            activation2 = self.ACTIVATION?(layer2)\n",
    "            layer3 = self.encodedlayer(activation2)\n",
    "            activation3 = self.ACTIVATION?(layer3)\n",
    "            layer4 = self.hiddenlayer3(activation3)\n",
    "            activation4 = self.ACTIVATION?(layer4)\n",
    "            layer5 = self.hiddenlayer4(activation4)\n",
    "            activation5 = self.ACTIVATION?(layer5)\n",
    "            layer6 = self.outputlayer(activation5)\n",
    "            output = self.ACTIVATION?(layer6)\n",
    "\n",
    "            # Why do I have two outputs?\n",
    "            return output, layer3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSr4XllBX-Nb",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "This is going to be a lot of guess-and-check. You've been warned. In this block, we will train the autoencoder. Add a plotting function into the training.\n",
    "\n",
    "Note that instead of cross-entropy, we use the \"mean-square-error\" loss. Switch between SGD and Adam optimized. Which seems to work better? Optimize the `learning-rate` parameter and do *not* change other parameters, like momentum.\n",
    "\n",
    "Write a piece of code to run train_model for 10 epochs. Play with the size of each hidden layer and encoded layer. When you feel you've found a reasonable learning rate, up this to 100 (or even 500 if you're patient) epochs. Hint: You want to find MSE~0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qYsd2nlo8Nu",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_model(training_data,test_data, model):\n",
    "  # define the optimization\n",
    "  criterion = torch.nn.MSELoss()\n",
    "\n",
    "  # Choose between these two optimizers\n",
    "  #optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005,weight_decay=1e-6)\n",
    "\n",
    "  for epoch in range(500):\n",
    "    # clear the gradient\n",
    "    optimizer.zero_grad()\n",
    "    # compute the model output\n",
    "    myoutput, encodings_train = model(training_data)\n",
    "    # calculate loss\n",
    "    loss = criterion(myoutput, training_data)\n",
    "    # credit assignment\n",
    "    loss.backward()\n",
    "    # update model weights\n",
    "    optimizer.step()\n",
    "    print(epoch,loss)\n",
    "    # STUDENTS ADD THIS PART\n",
    "    output_test, encodings_test = model(test_data)\n",
    "    loss_test = criterion(output_test, test_data)\n",
    "    plt.plot(epoch,loss.detach().numpy(),'ko')\n",
    "    plt.plot(epoch,loss_test.detach().numpy(),'ro')\n",
    "  plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SARJPAH1piaS",
    "outputId": "9af48944-d529-400e-e9ee-1df416aa90d1",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Autoencoder(np.shape(images_train[0])[0],50,50,10)\n",
    "train_model(images_train, images_test, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zWYWVOuYvP4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Understand our Results\n",
    "\n",
    "Plot an image with imshow, and plot the autoencoder output for the same galaxy. Try plotting the difference between the two. What does your algorithm do well reconstructing? Are there certain features which it fails to reproduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "bxSqYo4Ap1HA",
    "outputId": "f187dfcd-6804-4859-da3b-a0ff072e2a5e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "yhat, test_encodings = model(images_test)\n",
    "yhat = yhat.detach().numpy()\n",
    "\n",
    "yhat = np.reshape(yhat,(len(images_test),43,43))\n",
    "image_reshaped = np.reshape(images_test,(len(images_test),43,43))\n",
    "rand_int = int(np.random.choice(np.arange(len(yhat))))\n",
    "plt.imshow(yhat[rand_int])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image_reshaped[rand_int])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(yhat[rand_int] - image_reshaped[rand_int].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5YQIsfC7C9n",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Latent Space \n",
    "\n",
    "Make a scatter plot of two of the 10 latent space dimensions. Do you notice any interesting correlations between different subsets of the latent space? Any interesting clustering?\n",
    "\n",
    "Try color coding each point by the galaxy label using `plt.scatter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "14oCFX6Wvffl",
    "outputId": "703b79a3-af9d-44f5-b522-62781416f066",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.argmax(labels_test, axis=1)\n",
    "\n",
    "plt.scatter(test_encodings[0:500,1].detach().numpy(),\n",
    "            test_encodings[0:500,3].detach().numpy(),\n",
    "            # YOUR CODE HERE\n",
    "            c = ...)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL5yNDE37TCE",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Playing with the Latent Space\n",
    "\n",
    "Create a random forest classifier to classify each galaxy using only your latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "BtBA7LDkznuO",
    "outputId": "b68056eb-2309-406e-b404-146b6fcda45a",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "yhat, train_encodings = model(images_train)\n",
    "\n",
    "clf.fit(train_encodings.detach().numpy(), labels_train)\n",
    "new_labels = clf.predict(test_encodings.detach().numpy())\n",
    "\n",
    "new_indices = np.argmax(new_labels, axis=1)\n",
    "\n",
    "cm = confusion_matrix(indices,new_indices,normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xeo_dn8j7fNd",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Create an isolation forest to find the most anomalous galaxies. Made a cumulative distribution plot showing the anomaly scores of each class of galaxies. Which ones are the most anomalous? Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "SjWqRJjgOTKf",
    "outputId": "667ff60a-3561-496b-f90c-815a5c30a229",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "encodings = test_encodings.detach().numpy()\n",
    "labels = labels_test.detach().numpy()\n",
    "clf = IsolationForest(random_state=0,n_estimators=1000).fit(encodings)\n",
    "scores = -clf.score_samples(encodings)\n",
    "print(labels[np.argmax(scores)])\n",
    "plt.imshow(yhat[np.argmax(scores)].detach().numpy().reshape(43,43))\n",
    "plt.show()\n",
    "plt.clf()\n",
    "def cdf(x, label='',plot=True, *args, **kwargs):\n",
    "    x, y = sorted(x), np.arange(len(x)) / len(x)\n",
    "    return plt.plot(x, y, *args, **kwargs, label=label) if plot else (x, y)\n",
    "\n",
    "ulabels = np.unique(indices)\n",
    "for ulabel in ulabels:\n",
    "  gind = np.where(indices==ulabel)\n",
    "  cdf(scores[gind],label=str(ulabel))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rvu91ZyEFtBQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variational AutoEncoders (VAEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vg7JmIrF8PD",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Probabilistic Interpretation\n",
    "\n",
    "**In a Variational Auto-Encoder we interpret the reconstruction task  probabilistically:**\n",
    "\n",
    "Compressing the data results in a loss of information about the original data. \n",
    "If we only have access to the compressed data, we have no chance of knowing what the original data looked like *exactly*. Instead, we obtain a probability distribution over possible inputs.\n",
    "\n",
    "This motivates a probabilistic formulation of the problem: \n",
    "Let's assume that the data follows some probabiliy distribution $p(x)$ (each data point is a drawn from this distribution)\n",
    "\n",
    "$$ p(x) = \\int \\mathrm{d}z\\, p(x|z) p(z) \\tag{3}$$\n",
    "\n",
    "Here, we have introduced two probability distributions on the right hand side, the liklelihood, $p(x|z)$, and the prior, $p(z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The likelihood arises because of the information loss in the compression.\n",
    "\n",
    "$$ x = g_\\psi(f_\\phi(x)) + \\epsilon = g_\\psi(z) + \\epsilon \\tag{4}$$ \n",
    "\n",
    "Ideally, $\\epsilon$, the part of the data that is lost in the compression, is just noise and unimportant for our final data analysis. The form of the likelihood is equal to the distribution of this noise. For example, if the noise is Gaussian (which is often the case for physical data) with covariance $\\Sigma_\\epsilon$, the likelihood is a Gaussian distribution:\n",
    "\n",
    "$$ p_{\\psi}(x|z) = \\mathcal{G}(g_\\psi(z),\\Sigma_\\epsilon) \\tag{5}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Starting from $p(x|z) = \\int \\mathrm{d}\\epsilon\\, p(x,\\epsilon|z)$ can you show that the likelihood follows the same distribution as $\\epsilon$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$p(x|z) = \\int \\mathrm{d}\\epsilon\\, p(x,\\epsilon|z) = \\int \\mathrm{d}\\epsilon\\, p(x|z,\\epsilon) p(\\epsilon) = \\int \\mathrm{d}\\epsilon\\, \\delta_D(x-g(z)-\\epsilon) p(\\epsilon) = p(x-g(z))$ \n",
    "\n",
    "The prior, $p(z)$, is the average distribution of the encoded data.\n",
    "\n",
    "$$ p(z) = \\int \\mathcal{d}x\\, p(z|x) p(x) \\tag{6}$$\n",
    "\n",
    "In a VAE, we want the prior distribution to have closed form and to be easy to sample from (for artificial data generation). We have the freedom to choose the prior distribution as a constraint. The network training will ensure it is obeyed. A common choice is a normal distribution\n",
    "\n",
    "$$ p(z) = \\mathcal{N}(0,1) \\tag{7} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Variational Autoencoder & Evidence Lower BOund (ELBO)\n",
    "\n",
    "To train the Variational Auto-Encoder we maximize the average log probability, $\\log p(x)$, or, as we will see now, a lower bound to this quantity.\n",
    "\n",
    "Equation (3) involves solving a fairly high dimensional integral, which is a computationally expensive and sometimes infeasible operation. This integral has to be solved not only once, but in each training step. Variational Autoencoders  solve this integral approximately by using a variational ansatz for the posterior distribution, the approximate posterior $q_\\phi(z|x)$. This distribution approximates the true posterior p(z|x) and is parameterized by the encoder parameters $\\phi$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The classic choice for the variational posterior is a multivariate Gaussian in the mean field approxiation (mean field meaning no off-diagonal terms in the covariance)\n",
    "\n",
    "$$ q_\\phi(z|x) = \\mathcal{G}(\\mu,\\sigma_i) \\tag{7} $$\n",
    "\n",
    "where the mean, $\\mu$, and variance, $\\sigma$, are determined by the encoder network. \n",
    "\n",
    "$$(\\mu, \\sigma) = f_\\phi(x) \\tag{8} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The variational ansatz allows us to formulate a lower bound to $\\log p(x)$, the Evidence Lower BOund.\n",
    "\n",
    "$$ \\log p(x) >= \\int \\mathrm{d}z\\, q_\\phi(z|x) \\log{p_\\psi(x|z)} - \\int \\mathrm{d}z\\, q_\\phi(z|x) \\log{\\frac{q_\\phi(z|x)}{p(z)}} = ELBO \\tag{8}$$\n",
    "\n",
    "$$ \\mathcal{L}_{VAE}(\\phi,\\psi) = -ELBO \\tag{9}$$\n",
    "\n",
    "The ELBO consists of two terms. The first term measures the expectation value of the likelihood over the posterior. Maximizing this term encourages high quality reconstructions (similar to the autoencoder). The second term is the KL-Divergence (a distance measure) between the variational posterior and the prior. This term acts as a regularizer. It encourages posterior distributions which are similar to the prior.\n",
    "\n",
    "In VAE training the first term is evaluated stochastically, meaning that the expectation value is evaluated approximately by averaging over a number of samples from $q_\\phi(z|x)$. The second term can be either evaluated analytically (the KL divergence between to Gaussian distributions can be calculated) or stochastically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reparametrization Trick\n",
    "\n",
    "Minimizing Eq. (9) requires taking gradients with respect to $\\phi$ and $\\psi$. But how do we take the gradient through an expectation value?  \n",
    "\n",
    "We use what is called the reparametrization trick. Instead of sampling from the posterior $q_\\phi(z|x)$ we sample from the parameter-independent normal distribution\n",
    "\n",
    "$$ \\zeta ∼ \\mathcal{N}(0,1) \\tag{10}$$\n",
    "\n",
    "and use the identity $z=\\zeta*\\sigma_\\phi+\\mu_\\phi$, an operation which is trivially differentiably, to obtain our samples.\n",
    "\n",
    "Pytorch will perform the reparametrization trick for us under the hood, if we use *distribution.rsample()* - so we don't have to code it explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNZMyGZEuMJY",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let' start by importing a few packages, that we will need later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iquM2NAFde_",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDLVu9iy4BFu",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Our dataset\n",
    "\n",
    "In this coding exercise we will be working with a galaxy spectra sample from the SDSS-BOSS DR 16 release. The spectra have been de-redshifted to the restframe and their magnitude has been standardized to a distance correspondingg to $z_\\lambda=0.1$. They have further been downsampled to 1000 pixels, denoised and inpainted where masks were present.\n",
    "\n",
    "(I can tell you more about the data cuts and preprocessing if you are interested, but it is not relevant for this task.)\n",
    "\n",
    "Despite being relatively high-dimensional ($d=1000$), galaxy spectra actually reside on a lower dimensional manifold. An indication for this is that we can compress them to much smaller dimensionality without sacrificing much reconstruction quality. \n",
    "\n",
    "This property makes them a very suitable data type for VAEs. \n",
    "\n",
    "(The same applies to image data, but images datasets are computationally more expensive to train on and they need more complicated nework architectures - things that we don't want to worry about in this exercise.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DK4VXXUUq4vi",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "STEP 1: Download the training and test datasets \n",
    "\n",
    "1.   [training set](https://drive.google.com/file/d/1ZYjTo4GGfFJPJgtmgj2adaUNQb9SzImo/view?usp=sharing)\n",
    "2.   [test set](https://drive.google.com/file/d/1w-PbHKkk3-eIxurWvosARSKufOKnp3zN/view?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwlmXPZpxnyo",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's set some immutable variables:\n",
    "The dimensionality of the input data and the dimensionality of the latent (encoded) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMnt57iDXqIJ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE      = 1000\n",
    "LATENT_SIZE     = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KU4ULbV5x0wd",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next we create pytorch datasets from the training and test data (note that you need to change the root_dir, if you placed the data in a different folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhaWK_EWF7R_",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class SDSS_DR16(Dataset):\n",
    "    \"\"\"De-redshifted and downsampled spectra from SDSS-BOSS DR16\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir='drive/MyDrive/ML_lecture_data/', transform=True, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory of data file\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "\n",
    "        if train:\n",
    "            self.data = np.load(open('./DR16_denoised_inpainted_train.npy','rb'),allow_pickle=True)\n",
    "        else:\n",
    "            self.data = np.load(open('./DR16_denoised_inpainted_test.npy','rb'),allow_pickle=True)\n",
    "\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "        self.mean = torch.mean(self.data)\n",
    "        self.std  = torch.std(self.data)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = (self.data[idx]-self.mean)/self.std\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "#initialize datasets\n",
    "training_data = SDSS_DR16(train=True)\n",
    "test_data     = SDSS_DR16(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYciZ7mJ3CvT",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##**Autoencoder**\n",
    "This exercise starts with an Autoencoder, which is already implemented and working. The next cells walk you through the code. Your task (further below) will be to take that code and modify it into a Variational Autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXtpdS3OyG5Y",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, we define our encoder and decoder networks. We use a very simple MLP, with two linear layers and one non-linear activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1udif2UYQOw",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# we inherit from pytorch Module class; https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, seed=853):\n",
    "        \"\"\"\n",
    "        seed: int, random seed for reproducibility\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        # here we are initializing the linear layers. This registeres the layer parameters (W,b) as parameters of the Module\n",
    "        self.fc1 = nn.Linear(INPUT_SIZE,50)\n",
    "        self.fc2 = nn.Linear(50,LATENT_SIZE)\n",
    "\n",
    "    # this defines a forward pass of the network (=\"applying\" the network to some input data)\n",
    "    def forward(self, x):\n",
    "        x      = torch.nn.LeakyReLU()(self.fc1(x))\n",
    "        z      = self.fc2(x)\n",
    "        return z\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, seed=620):\n",
    "        \"\"\"\n",
    "        seed: int, random seed for reproducibility\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(LATENT_SIZE,50)\n",
    "        self.fc2 = nn.Linear(50,INPUT_SIZE)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = torch.nn.LeakyReLU()(self.fc1(z))\n",
    "        x = self.fc2(z)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wt_mADqDy3cD",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Having defined the encoder and decoder network, we can move on to define the Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGzcsBeeau1t",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # here we are creating instances of the Encoder and Decoder class\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2yyNsVUcNR-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This creates an instance of the Autoencoder class\n",
    "AE = Autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEuNOP4N0X0O",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The next step is to train the Autoencoder. This is what a generic training loop looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lH1elQeObtEE",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the training loop takes a function that loads the data batch by batch, a model to train, a loss function to train the model on and an optimizer\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    losses = []\n",
    "    # iterate over the dataset\n",
    "    for batch, X in enumerate(dataloader):\n",
    "        # Compute prediction of the model (in case of the AE the prediction is the reconstructed data)\n",
    "        pred = model(X)\n",
    "        # Compute the loss function (in case of the AE this is the L2 distance to the input data)\n",
    "        loss = loss_fn(pred,X)\n",
    "\n",
    "        # Backpropagation; this is where we take the gradient and update the network parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # here we keep track of the loss\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            losses.append(loss)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "\n",
    "# the test loop is similar to the training loop, only that we don't take any gradients/don't update the network parameters, but only evaluate\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss =  0\n",
    "    with torch.no_grad():\n",
    "        for X in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, X).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\" Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KqrUXUY3KW-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the next cell we set the training parameters, define the loss function and create DataLoaders. Pytorch DataLoaders manage the data loading for us (break the dataset into batches, keep track of epochs, reshuffle the data after each epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9brCNsq0m8N",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "BATCHSIZE       = 128\n",
    "BATCHSIZE_TEST  = 256\n",
    "LEARNING_RATE   = 1e-3\n",
    "\n",
    "# MeanSquaredError (L2) Loss\n",
    "loss_fn         = nn.MSELoss()\n",
    "# Adam Optimizer\n",
    "optimizer       = torch.optim.Adam(AE.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCHSIZE, shuffle=True)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=BATCHSIZE_TEST, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrVfwZ6x3ytf",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It's finally time for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wO2GEEoEffAk",
    "outputId": "f8fe66cc-da19-4b5d-8ff4-5c251f6a050c",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "SEED   = 555  \n",
    "\n",
    "train_loss = []\n",
    "test_loss  = []\n",
    "for t in range(EPOCHS):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss.append(train_loop(train_dataloader, AE, loss_fn, optimizer))\n",
    "    test_loss.append(test_loop(test_dataloader, AE, loss_fn))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da7lOSzE4J6f",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's see how the model is doing. Let's look at \n",
    "\n",
    "1.   Training and test loss \n",
    "2.   Final reconstruction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "24qdCadyhXVU",
    "outputId": "3a767800-acd4-44b3-cfda-dd359be6ef58",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# losses\n",
    "length = len(np.asarray(train_loss).flatten())\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,length*100,length), np.asarray(train_loss).flatten(),label='training set')\n",
    "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss,label='test set')\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### zoom in \n",
    "length = len(np.asarray(train_loss).flatten())\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,length*100,length), np.asarray(train_loss).flatten(),label='training set')\n",
    "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss,label='test set')\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.ylim(0,0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZA9Vz3-5Di-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can see that the model had a really easy time learning the task and that we haven't overfitted yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4hzPWZP5Um8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, let's look at a few reconstructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "GVVJ6vwUASd1",
    "outputId": "fa52daed-1d29-41d5-c2bc-07fee2ac2d5c",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_input = next(iter(test_dataloader))\n",
    "\n",
    "with torch.no_grad():\n",
    "  recons = AE(test_input)\n",
    "\n",
    "# This is the mapping from pixel to the de-redshifted (rest) wavelength\n",
    "wlmin, wlmax      = (3388,8318)\n",
    "fixed_num_bins    = 1000\n",
    "wl_range          = (np.log10(wlmin),np.log10(wlmax))\n",
    "wl                = np.logspace(wl_range[0],wl_range[1],fixed_num_bins)\n",
    "\n",
    "fig, ax = plt.subplots(4,4, figsize=(20,10), sharex=True)\n",
    "ax = ax.flatten()\n",
    "for ii in range(16):\n",
    "  ax[ii].plot(wl,test_input[ii], label='input')\n",
    "  ax[ii].plot(wl,recons[ii],alpha=0.7,label='reconstruction')\n",
    "  if ii in np.arange(12,16):\n",
    "    ax[ii].set_xlabel('wavelength [Ångströms]')\n",
    "  if ii in [0,4,8,12]:\n",
    "    ax[ii].set_ylabel('some standardized flux')\n",
    "  if ii==0:\n",
    "    ax[ii].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oqkoegOKP3G",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "... and the average reconstruction error as a function of wavelength:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "JyHOlus2I3zE",
    "outputId": "2c6863b8-a7a7-4d97-9795-74a12b45ad86",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "avg_loss  = 0\n",
    "with torch.no_grad():\n",
    "    for X in test_dataloader:\n",
    "        pred = AE(X)\n",
    "        avg_loss+=np.mean((pred.cpu().numpy()-X.cpu().numpy())**2,axis=0)/(len(test_data)//BATCHSIZE_TEST)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(wl,np.sqrt(avg_loss))\n",
    "plt.ylabel('average reconstruction error')\n",
    "plt.xlabel('wavelength [Ångströms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VisR7dVUTqzk",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Optional: save the model weights\n",
    "#torch.save(AE.state_dict(), './AE_model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG9cNGp7Rnda",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A few things you might have noticed and that can be useful to keep in mind:\n",
    "\n",
    "\n",
    "*   The model expects a single precision input. You can change the type of a tensor with tensor_name.type(), where tensor_name is the name of your tensor and type is the dtype. For typecasting into single precision floating points, use float(). A numpy array is typecasted with array_name.astype(type). For single precision, the type should be np.float32.\n",
    "*   Before we analyze tensors we often want to convert them to numpy arrays with tensor_name.numpy()\n",
    "*   If pytorch has been tracking operations that resulted in the current tensor value, you need to detach the tensor from the graph before you can transform it into a numpy array: tensor_name.detach(). Scalars can be detached with scalar.item()\n",
    "*   If you tensor is currently on the GPU, you can bring it onto the CPU with tensor_name.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtndaU2ubVov",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Variational Autoencoder**\n",
    "\n",
    "Your task is to transform the above Autoencoder into a Variational Autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6YJ6mtGLwS4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We start by modifying the encoder network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGEjVfDFNRvl",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### **STEP 1:** Modify the encoder network.\n",
    "The encoder network is used to characterize the variational distribution q(z|x). Recall that we want q(z|x) to be a Gaussian with diagonal covariance. An N-dimensional Gaussian with diagonal covariance is eqivalent to N independent 1-dimensional Gaussians (where N is the latent size). Each Gaussian is defined by two quantities, its mean and variance (or, if we take the sqrt, the standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKMNpHaeb93k",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class VAEEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seed=853):\n",
    "        super(VAEEncoder, self).__init__()\n",
    "        # TASK: change the output size of the encoder network. How many parameters must it return to define q(z|x)?\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(INPUT_SIZE,50)\n",
    "        # CHANGE HERE\n",
    "        self.fc2 = nn.Linear(50,??)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TASK: change the output of the encoder network. Instead of just returning z, it should return z and ...?\n",
    "        # HINT: Don't forget that the standard deviation/variance must be strictly positive!\n",
    "        # HINT: You might want to use torch.split(): https://pytorch.org/docs/stable/generated/torch.split.html\n",
    "        x      = torch.nn.LeakyReLU()(self.fc1(x))\n",
    "        x      = self.fc2(x)\n",
    "        # CHANGE HERE\n",
    "        mu,std = torch.split(...\n",
    "        std    = torch.exp(std) + 1e-8\n",
    "        return mu, std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4X2ctPEO2tF",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### **STEP 2:** Modify the decoder network.\n",
    "\n",
    "We will leave our decoder network as it is :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-_V5PYNMNSy",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class VAEDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seed=620):\n",
    "        super(VAEDecoder, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(LATENT_SIZE,50)\n",
    "        self.fc2 = nn.Linear(50,INPUT_SIZE)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = torch.nn.LeakyReLU()(self.fc1(z))\n",
    "        x = self.fc2(z)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgn_SFibPDPj",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since we work with probability distributions in the VAE, we need to import the torch distributions package. We will only need the normal distribution for this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8pX6vYGS0nJ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#TASK: Familiarize yourself with torch.distribution.Normal - you can find the documentation here: https://pytorch.org/docs/stable/distributions.html#normal\n",
    "#HINT: It takes a standard deviation (scale) not a variance as input\n",
    "from torch.distributions import Normal as Normal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLmhg1d9Pkm-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### **STEP 3:** Modify the AE class into a VAE class!\n",
    "\n",
    "\n",
    "\n",
    "1.   A VAE has a few more input parameters than an AE. We need a sample size, which determines how many samples we draw from $q_\\phi(z|x)$ for evaluating the ELBO. We also need a $\\sigma_\\epsilon$ to characterize the likelihood, $p_\\psi(x|z)=\\mathcal{G}(x',\\sigma_\\epsilon)$.\n",
    "2.   The prior is fixed. We can define it in the beginning, when we initialize the VAE.\n",
    "3.   We need methods to compute the variational posterior, the likelihood, the KL-divergence and the ELBO.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IblX0IgkbcMI",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    #TASK: add parameters mentioned in point 1. \n",
    "    def __init__(self, sample_size, sigma):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = VAEEncoder()\n",
    "        self.decoder = VAEDecoder()\n",
    "        self.sample_size = sample_size\n",
    "        self.sigma       = sigma\n",
    "        #TASK: Use the Normal class to define the prior (a standard normal distribution), p(z)\n",
    "        self.prior       = Normal(...\n",
    "\n",
    "    def change_sample_size(self,sample_size):\n",
    "        self.sample_size = sample_size\n",
    "        return True\n",
    "\n",
    "    def get_q(self,x):\n",
    "        mu, std = self.encoder(x)\n",
    "        self.q = Normal(mu, std)\n",
    "        return True\n",
    "\n",
    "    def sample_q(self):\n",
    "        z_sample = self.q.rsample(torch.Size([self.sample_size]))\n",
    "        return z_sample\n",
    "\n",
    "    def get_avg_log_likelihood(self,recons,x):\n",
    "        #TASK: Write a method that returns the first term in the ELBO (this method should define the likelihood and evaluate the average log likelihood of the reconstruction)\n",
    "        #HINT: Pay attention to shapes. The function should return an average log likelihood (a single number) for every data point in the batch.\n",
    "        #HINT: The output shape of Normal(mu, sigma).log_prob() is a little unintuitive. If mu or sigma are N-dimensional, it returns N results (applies N independent Gaussians). \n",
    "        #HINT: You need to average over samples from q to obtain the final result.               \n",
    "        ll    = Normal(...\n",
    "        log_p = ll.log_prob(...\n",
    "        log_p = torch.sum(...\n",
    "        return torch.mean(...\n",
    "\n",
    "    def stochastic_kl_divergence(self,z_sample):\n",
    "        return torch.mean(torch.sum(self.q.log_prob(z_sample),dim=-1)-torch.sum(self.prior.log_prob(z_sample),dim=-1), dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #TASK: a forward pass should return the two terms in the ELBO\n",
    "        #HINT: use all the methods we defined above\n",
    "        self.get_q(x)\n",
    "        samples = self.sample_q()\n",
    "        recons  = self.decoder(...\n",
    "        log_likelihood = self.get_avg_log_likelihood(...\n",
    "        kl      = self.stochastic_kl_divergence(...\n",
    "        return log_likelihood, kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox7VgW-R6W6P",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### **STEP 4**: Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DYaUij-WkK3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#TASK: create an instance of the Variational Autoencoder with sample_size=4 and sigma=1\n",
    "VAE = VariationalAutoencoder(4,sigma=1)\n",
    "\n",
    "optimizer = torch.optim.Adam(VAE.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "#from torch.optim.lr_scheduler import StepLR\n",
    "#scheduler = StepLR(optimizer, step_size=10, gamma=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zw8MYTJWW4N8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#TASK: define the new loss function\n",
    "def negative_ELBO(avg_log_likelihood,kl):\n",
    "\n",
    "    negative_ELBO = - torch.mean(avg_log_likelihood-kl)\n",
    "\n",
    "    return negative_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yjd0yE4WrKc",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    losses = []\n",
    "    for batch, X in enumerate(dataloader):\n",
    "        #TASK: compute the loss from the output of the VAE foward pass  \n",
    "        log_likelihood, kl = model(X)\n",
    "        loss = loss_fn(log_likelihood,kl)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            losses.append(loss)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    #scheduler.step()\n",
    "    return losses\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, nllh, kl_ = 0, 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X in dataloader:\n",
    "            #TASK: in the test loop we want to keep track not only of the ELBO, but also of the two terms that contribute to the ELBO (kl diveregence and loglikelihood)\n",
    "            log_likelihood, kl = model(X)\n",
    "            test_loss += loss_fn(log_likelihood,kl).item()\n",
    "            nllh += -np.mean(log_likelihood.cpu().numpy())\n",
    "            kl_ += np.mean(kl.cpu().numpy())\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    kl_ /= num_batches\n",
    "    nllh /= num_batches\n",
    "\n",
    "    print(f\" Avg test loss      : {test_loss:>8f}\")\n",
    "    print(f\" Avg KL             : {kl_:>8f}\")\n",
    "    print(f\" Avg negative log likelihood : {nllh:>8f} \\n\")\n",
    "\n",
    "    return test_loss, kl_, nllh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZMlhzGoYJvX",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's train!    \n",
    "**Note:** Training a VAE can be unstable. If things get weird, try changing the random seed or hyperparameters, such as the number of epochs, batchsize, learning rate, sample size, likelihood noise level...\n",
    "\n",
    "**HINT:** To get good artificial data samples, you need to have a KL divergence in the single digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Udr9UnLXmJf",
    "outputId": "073342b7-29df-4685-8aa0-33601d78e839",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 8\n",
    "SEED   = 123\n",
    "\n",
    "train_loss = []\n",
    "test_loss  = []\n",
    "for t in range(EPOCHS):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss.append(train_loop(train_dataloader, VAE, negative_ELBO, optimizer))\n",
    "    test_loss.append(test_loop(test_dataloader, VAE, negative_ELBO))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXZtkOVVFuNK",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_loss = np.asarray(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "7syew_eAXpfj",
    "outputId": "da058c9e-e7f2-4207-abe4-90fdf408a711",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#TASK: plot the training loss, test loss, and the contributions to the loss from each of the two terms \n",
    "length = len(np.asarray(train_loss).flatten())\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,length*100,length), np.asarray(train_loss).flatten(),label='training set')\n",
    "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss[:,0],label='test set loss')\n",
    "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss[:,1],label='test set kl')\n",
    "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss[:,2],label='test set neg log likelihood')\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0tcAyjRaZ8W",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## TASK: Inspect how the contribution of the kl divergence and log likelihood to the loss change as you change the noise in the likelihood. Some suggested values: sigma=[0.5,1,2]\n",
    "## TASK: what happens when you change the number of samples?\n",
    "### What do you observe? Can you interpret it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6RbwE2BXxrU",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### **STEP 5:** Inspect the model performance\n",
    "\n",
    "Similar to the AE, we will look at the average reconstruction quality. But in addition, we also want to know how well the kl term was minimized. We will therefore look at three things\n",
    "\n",
    "1.   Reconstruction quality\n",
    "2.   Scatter plots of posterior samples and prior samples. Recall that $p(z)=\\int \\mathcal{d}x\\, p(x,z) \\approx \\frac{1}{N_{samples}} \\sum_{x\\sim p(x)} p(z|x)$.\n",
    "3.   Quality of artificial data generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: plot the average reconstruction error of the model as a function of wavelength (similar to above). How does it compare to the Autoencoder?\n",
    "\n",
    "Use the mean of $q(z|x)$ as the latent point for data x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "OvdilGwgXmKU",
    "outputId": "103639ea-fa65-4fa5-f6e4-14d10e5d83d5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "avg_loss  = 0\n",
    "VAE.eval()\n",
    "with torch.no_grad():\n",
    "    for X in test_dataloader:\n",
    "        pred = VAE.decoder(VAE.encoder(X)[0])\n",
    "        avg_loss+=np.mean((pred.cpu().numpy()-X.cpu().numpy())**2,axis=0)/(len(test_data)//BATCHSIZE_TEST)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(wl,np.sqrt(avg_loss))\n",
    "plt.ylabel('average reconstruction error')\n",
    "plt.xlabel('wavelength [Ångströms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### TASK: make a corner plot of posterior samples. Does the average posterior match the prior?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9zbCDqW93Vwp",
    "outputId": "c1cb33f1-edab-4fe2-dec2-88a71a8b45e9",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "VAE.eval()\n",
    "with torch.no_grad():\n",
    "    for ii, X in enumerate(test_dataloader):\n",
    "        VAE.get_q(X)\n",
    "        prior_sample = VAE.prior.sample([BATCHSIZE_TEST])\n",
    "        sample       = VAE.sample_q().cpu().numpy()[0:1].swapaxes(0,1)\n",
    "        if ii==0:\n",
    "          samples       = sample\n",
    "          prior_samples = prior_sample\n",
    "        else:\n",
    "          samples       = np.vstack([samples, sample])\n",
    "          prior_samples = np.vstack([prior_samples, prior_sample])\n",
    "\n",
    "samples       = np.reshape(samples,[-1, LATENT_SIZE])\n",
    "prior_samples = np.reshape(prior_samples,[-1, LATENT_SIZE])\n",
    "\n",
    "print(samples.shape)\n",
    "print(prior_samples.shape)\n",
    "\n",
    "data1    = pd.DataFrame()\n",
    "data2    = pd.DataFrame()\n",
    "\n",
    "for ii in range(LATENT_SIZE):\n",
    "  data1['dim_%d'%ii] = samples[:,ii]\n",
    "data1['source'] = 'posterior'\n",
    "\n",
    "for ii in range(LATENT_SIZE):\n",
    "  data2['dim_%d'%ii] = prior_samples[:,ii]\n",
    "data2['source'] = 'prior'\n",
    "\n",
    "data = pd.concat([data1,data2]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#HINT: to get a density estimate you can set kind='kde', but you'll probably have to reduce the number of samples, KDE optimization scales pretty badly with number of samples\n",
    "sns.pairplot(data,corner=True,kind='scatter', hue='source', plot_kws={'s':4})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62rkkkwbewKi",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## TASK: Generate artificial data: sample from the prior and foward model the sample thorugh the decoder. Do the samples look realistic? Why?/Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "YhYlgfZLm_iI",
    "outputId": "ec9a0cc7-07ea-444c-cac6-4f9f6b2464c0",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "VAE.eval()\n",
    "with torch.no_grad():\n",
    "  samples = VAE.prior.sample([16])\n",
    "  data_samples = VAE.decoder(samples)\n",
    "\n",
    "# This is the mapping from pixel to the de-redshifted (rest) wavelength\n",
    "wlmin, wlmax      = (3388,8318)\n",
    "fixed_num_bins    = 1000\n",
    "wl_range          = (np.log10(wlmin),np.log10(wlmax))\n",
    "wl                = np.logspace(wl_range[0],wl_range[1],fixed_num_bins)\n",
    "\n",
    "fig, ax = plt.subplots(4,4, figsize=(20,10), sharex=True)\n",
    "ax = ax.flatten()\n",
    "for ii in range(16):\n",
    "  ax[ii].plot(wl,data_samples[ii], label='artificial data')\n",
    "  if ii in np.arange(12,16):\n",
    "    ax[ii].set_xlabel('wavelength [Ångströms]')\n",
    "  if ii in [0,4,8,12]:\n",
    "    ax[ii].set_ylabel('some standardized flux')\n",
    "  if ii==0:\n",
    "    ax[ii].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
